{\rtf1\ansi\ansicpg1252\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl460\partightenfactor0

\f0\fs40 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 import java.io.IOException;\cf0 \strokec0 \
\cf2 \strokec2 import java.util.StringTokenizer;\cf0 \strokec0 \
\cf2 \strokec2 import org.apache.hadoop.conf.Configuration;\cf0 \strokec0 \
\cf2 \strokec2 import org.apache.hadoop.fs.Path;\cf0 \strokec0 \
\cf2 \strokec2 import\cf0 \strokec0 \
\cf2 \strokec2 org.apache.hadoop.io\cf0 \strokec0 \
\cf2 \strokec2 .IntWritable;\cf0 \strokec0 \
\cf2 \strokec2 import org.apache.hadoop.io.Text;\cf0 \strokec0 \
\cf2 \strokec2 import org.apache.hadoop.mapreduce.Job;\cf0 \strokec0 \
\cf2 \strokec2 import org.apache.hadoop.mapreduce.Mapper;\cf0 \strokec0 \
\cf2 \strokec2 import \cf0 \strokec0 \
\cf2 \strokec2 org.apache.hadoop.mapreduce.Reducer;\cf0 \strokec0 \
\cf2 \strokec2 import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\cf0 \strokec0 \
\cf2 \strokec2 import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\cf0 \strokec0 \
\cf2 \strokec2 public class WordCount \{\cf0 \strokec0 \
\cf2 \strokec2 public static class TokenizerMapper\cf0 \strokec0 \
\cf2 \strokec2 extends Mapper\cf0 \strokec0 \
\cf2 \strokec2 <Object, Text, Text, IntWritable> \{\cf0 \strokec0 \
\cf2 \strokec2 private final static IntWritable one = new IntWritable(1);\cf0 \strokec0 \
\cf2 \strokec2 private Text word = new Text();\cf0 \strokec0 \
\cf2 \strokec2 public void map(Object key, Text value, Context context\cf0 \strokec0 \
\cf2 \strokec2 ) throws IOException, InterruptedExcept\cf0 \strokec0 \
\cf2 \strokec2 ion \{\cf0 \strokec0 \
\cf2 \strokec2 StringTokenizer itr = new StringTokenizer(value.toString());\cf0 \strokec0 \
\cf2 \strokec2 while (itr.hasMoreTokens()) \{\cf0 \strokec0 \
\cf2 \strokec2 word.set(itr.nextToken());\cf0 \strokec0 \
\cf2 \strokec2 context.write(word, one);\cf0 \strokec0 \
\cf2 \strokec2 \}\cf0 \strokec0 \
\cf2 \strokec2 \}\cf0 \strokec0 \
\cf2 \strokec2 \}\cf0 \strokec0 \
\cf2 \strokec2 public static class IntSumReducer\cf0 \strokec0 \
\cf2 \strokec2 extends Reducer<Text, IntWritable, Text, IntWritable> \{\cf0 \strokec0 \
\cf2 \strokec2 private IntWritable result = new IntWritable();\cf0 \strokec0 \
\cf2 \strokec2 public void reduce(Text key, Iterable<IntWritable> values,\cf0 \strokec0 \
\cf2 \strokec2 Context context\cf0 \strokec0 \
\cf2 \strokec2 ) throws IOException, InterruptedException \{\cf0 \strokec0 \
\cf2 \strokec2 int sum = 0;\cf0 \strokec0 \
\cf2 \strokec2 for (IntWritable val : values) \{\cf0 \strokec0 \
\cf2 \strokec2 sum += val.get();\cf0 \strokec0 \
\cf2 \strokec2 \}\cf0 \strokec0 \
\cf2 \strokec2 result.set(sum);\cf0 \strokec0 \
\cf2 \strokec2 context.write(key, result);\cf0 \strokec0 \
\cf2 \strokec2 \}\cf0 \strokec0 \
}